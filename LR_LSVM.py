# -*- coding: utf-8 -*-
"""Miniproject 4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17evBnAiPF3mzOfu3nnvocWODkrSdCkdJ
"""

from sklearn.model_selection import KFold
import pandas as pd 
import numpy as np 
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer
from sklearn.preprocessing import OneHotEncoder
from sklearn import preprocessing
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt

def consistency(X,Y, k):
    mod = NearestNeighbors(n_neighbors=(k+1))
    mod.fit(X)
    sum = 0
    for i in range(len(X)):
        neighbors = mod.kneighbors([X[i]])
        for j in neighbors[1][0]:
            if j != i and (Y[i] != Y[j]):
                sum += 1
    return 1-sum/(len(X)*k)

def yDescCalc_adult(x,y):
  prot_present = 0
  prot_positive = 0
  Nprot_present = 0 
  Nprot_positive = 0
  for i in range(0,len(x)):
    if x[i][65]==1:
      prot_present += 1
      if y[i].strip() == ">50K":
        prot_positive += 1
    else:
      Nprot_present += 1
      if y[i].strip() == ">50K":
        Nprot_positive += 1
  descrim = abs((prot_positive/prot_present)-(Nprot_positive/Nprot_present))
  print("descrim: ", descrim)
  return descrim

def yDescCalc_german(x,y):
  prot_present = 0
  prot_positive = 0
  Nprot_present = 0 
  Nprot_positive = 0
  for i in range(0,len(x)):
    if x[i][9] <= 25:
      prot_present += 1
      if y[i] == 1:
        prot_positive += 1
    else:
      Nprot_present += 1
      if y[i] == 1:
        Nprot_positive += 1
  descrim = abs((prot_positive/prot_present)-(Nprot_positive/Nprot_present))
  print("descrim: ", descrim)
  return descrim
      

def optimize(x,y,model):
  my_scorer = make_scorer(accuracy_score)
  Cs = [0.001, 0.01, 0.1, 1, 10]
  gammas = [0.001, 0.01, 0.1, 1]
  loss = ['hinge','squared_hinge']
  tols = [1,1e-1,1e-2,1e-3,1e-4,1e-5]
  param_grids = {'C': Cs, 'tol' : tols}
  svr = GridSearchCV(model,
                   scoring = my_scorer,
                   cv=5,
                   param_grid=param_grids)
  svr.fit(x, y)
    #prediction = clf.predict(X_test)
  print(svr.best_params_)
  #print(svr.score(X_test, y_test))
  return svr.best_score_, svr.predict(X_test)

def german_load():
    X = []
    Y = []
    with open('german.data-numeric.txt', 'r') as f:
        for line in f:
            a = line.split()
            X.append([int(i) for i in a[:-1]])
            Y.append(int(a[-1]))
    return (X, Y)

def adult_load():
    numeric_features = ['age', 'ftnlwg', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']
    categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']

    data = pd.read_csv('adult.data.txt')

    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        #('scaler', StandardScaler())
        ])

    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))])

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)],
    sparse_threshold = 0)
    Y = data['earnings'].values
    X = data.drop('earnings', axis=1)

    return (preprocessor.fit_transform(X), Y)

kf = KFold(n_splits=5)
adult_X,adult_Y = adult_load()
german_X,german_Y = german_load()
print(len(german_Y))
print(len(adult_Y))
average_descrim = 0
average_acc = 0
average_consist = 0
for train_index, test_index in kf.split(adult_X):
    print("ADULT")
    X_train, X_test = adult_X[train_index], adult_X[test_index]
    y_train, y_test = adult_Y[train_index], adult_Y[test_index]
    clf = LinearSVC(C = 1, tol = 1)
    #clf = LinearSVC(C = 0.005, tol = 1) Linear SVM with higher lamda value for L2 regularizer
    #clf = LogisticRegression(C = 1, tol = 0.01)
    #ensem = RandomForestClassifier(clf)
    accuracy, prediction = optimize(X_test,y_test,clf)
    #clf.fit(X_train,y_train)
    #accuracy = clf.score(X_test,y_test)
    #prediction = clf.predict(X_test)
    average_descrim += yDescCalc_adult(X_test, prediction)
    average_acc += accuracy
    print("accuracy: ",accuracy)
    average_consist += consistency(X_test, prediction, 5)
print("Average descrim:", (average_descrim/5))
print("Average accuracy:", (average_acc/5))
print("Consistency:", (average_consist/5))
german_X=np.array(german_X)
german_Y=np.array(german_Y)
average_descrim = 0
average_consist = 0
average_acc = 0
for train_index, test_index in kf.split(german_X):
    print("GERMAN")
    X_train, X_test = german_X[train_index], german_X[test_index]
    y_train, y_test = german_Y[train_index], german_Y[test_index]
    #clf = LogisticRegression(C=1000000000000, penalty='l2') C is set very large so that lamba is essentially zero and hence no regularization
    clf = LogisticRegression(C=0.005, penalty='l2') Regularized Logistic Regression model
    #clf = LogisticRegression(C = 1, random_state=0, tol = 0.01, solver='lbfgs', multi_class='multinomial')
    #ensem = RandomForestClassifier(clf)
    accuracy, prediction = optimize(X_test,y_test,clf)
    #clf.fit(X_train,y_train)
    #accuracy = clf.score(X_test,y_test)
    #prediction = clf.predict(X_test)
    average_descrim += yDescCalc_german(X_test, prediction)
    average_acc += accuracy
    average_consist += consistency(X_test, prediction, 5)
    print("accuracy: ",accuracy)
print("Average descrim:", (average_descrim/5))
print("Average accuracy:", (average_acc/5))
print("Consistency:", (average_consist/5))
